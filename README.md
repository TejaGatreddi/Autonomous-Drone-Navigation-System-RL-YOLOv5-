# ğŸ›¸ Autonomous Drone Navigation System (RL + YOLOv5)

An intelligent reinforcement learningâ€“powered drone navigation project that enables autonomous flight, obstacle avoidance, and real-time perception using YOLOv5.  
This system integrates simulation (AirSim/Gazebo), ROS, and deep reinforcement learning to train drones to navigate safely in complex environments.

---

## ğŸš€ Overview

**Autonomous Drone Navigation System** is designed to train UAVs to understand their environment, avoid obstacles, and reach destination points using advanced machine learning.  
The project combines **Reinforcement Learning (PPO)**, **Object Detection (YOLOv5)**, and **Simulation Environments** to create a scalable and safe drone navigation pipeline.

---

## ğŸ§© Features

- ğŸ¤– **Reinforcement Learning (PPO)** â€” Drone learns optimal navigation behavior through training.  
- ğŸ›°ï¸ **AirSim/Gazebo Simulation** â€” Realistic physics environments for safe training.  
- ğŸ‘ï¸ **YOLOv5 Object Detection** â€” Real-time recognition of obstacles and dynamic objects.  
- âš™ï¸ **ROS Integration** â€” Perception and control nodes for real-time deployment.  
- ğŸ“¡ **Modular Architecture** â€” Easily extendable for real-world drones and custom hardware.  
- ğŸ§ª **Smoke Testing Mode** â€” Quick tests even without simulators installed.

---

## ğŸ§± Project Structure

```
autonav-drone/
â”‚
â”œâ”€â”€ sim/                     # AirSim/Gazebo environment connectors
â”‚   â”œâ”€â”€ airsim_env.py       
â”‚   â””â”€â”€ gazebo_env.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rl_envs/             # Gym-compatible RL environment
â”‚   â”‚   â””â”€â”€ gym_drone_env.py
â”‚   â”œâ”€â”€ agents/              # PPO RL agent
â”‚   â”‚   â””â”€â”€ ppo_agent.py
â”‚   â”œâ”€â”€ detection/           # YOLOv5 wrapper
â”‚   â”‚   â””â”€â”€ yolo_wrapper.py
â”‚   â”œâ”€â”€ ros_nodes/           # ROS-based perception & control nodes
â”‚   â”‚   â”œâ”€â”€ perception_node.py
â”‚   â”‚   â””â”€â”€ control_node.py
â”‚   â”œâ”€â”€ utils/               # Metrics, replay recorder
â”‚   â””â”€â”€ run_training.py      # Training entry point
â”‚
â”œâ”€â”€ docs/
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone this repository
```bash
git clone https://github.com/yourusername/autonav-drone.git
cd autonav-drone
```

### 2ï¸âƒ£ Create & activate virtual environment
```bash
python -m venv venv
source venv/bin/activate       # Mac/Linux
venv\Scripts\activate          # Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### ğŸ› ï¸ Run the RL training
```bash
python src/run_training.py --timesteps 200000
```

### ğŸ‘ï¸ Run YOLOv5 perception node (ROS)
```bash
python src/ros_nodes/perception_node.py
```

### ğŸ›« Run control node (ROS)
```bash
python src/ros_nodes/control_node.py
```

### ğŸ§ª Run smoke-test environment (no simulator needed)
```bash
python sim/airsim_env.py --mode smoke
```

---

## ğŸ“ˆ Example Output

| Component      | Output |
|----------------|--------|
| RL Reward      | Increasing trend as drone learns optimal paths |
| YOLOv5 Output  | Labels + bounding boxes for obstacles |
| Drone Control  | Real-time `/cmd_vel` commands |

---

## ğŸ§® Tech Stack

- **ML & RL:** PyTorch, Stable-Baselines3  
- **Simulation:** AirSim / Gazebo  
- **Detection:** YOLOv5  
- **Middleware:** ROS (rospy)  
- **Language:** Python  
- **Visualization:** Matplotlib  

---

## ğŸ§‘â€ğŸ’» Author

**TEJENDRA GATREDDI**  
ğŸ“ AI | ML | Robotics | Reinforcement Learning  
ğŸ“§ tgatredd@gitam.in  

---

## ğŸªª License

This project is licensed under the **MIT License**.

---

## â­ Contributing

Contributions are welcome!  
Open an issue or submit a pull request to enhance the system.

---

## ğŸŒŸ Acknowledgements

- Microsoft AirSim  
- Gazebo Simulation  
- Ultralytics YOLO  
- Reinforcement Learning Community  

---

> â€œAutonomy is achieved when perception, learning, and control work as one.â€
